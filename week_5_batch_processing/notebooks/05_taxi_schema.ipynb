{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4356a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d56c5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/03 14:06:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "#object for interacting with spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6feb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('data/raw/green/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e935210f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- lpep_pickup_datetime: string (nullable = true)\n",
      " |-- lpep_dropoff_datetime: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- trip_type: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a2f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to change schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd67735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_pd = pd.read_csv('data/raw/green/2021/01/green_tripdata_2021_01.csv.gz',nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0926c2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>2021-01-01 00:19:52</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>1.01</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:25:59</td>\n",
       "      <td>2021-01-01 00:34:44</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>2.53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>2021-01-01 00:51:55</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>2021-01-01 00:04:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1.99</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:16:36</td>\n",
       "      <td>2021-01-01 00:16:40</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-52.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2021-01-01 00:15:56   2021-01-01 00:19:52                  N   \n",
       "1         2  2021-01-01 00:25:59   2021-01-01 00:34:44                  N   \n",
       "2         2  2021-01-01 00:45:57   2021-01-01 00:51:55                  N   \n",
       "3         2  2020-12-31 23:57:51   2021-01-01 00:04:56                  N   \n",
       "4         2  2021-01-01 00:16:36   2021-01-01 00:16:40                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0           1            43           151                1           1.01   \n",
       "1           1           166           239                1           2.53   \n",
       "2           1            41            42                1           1.12   \n",
       "3           1           168            75                1           1.99   \n",
       "4           2           265           265                3           0.00   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0          5.5    0.5      0.5        0.00           0.0        NaN   \n",
       "1         10.0    0.5      0.5        2.81           0.0        NaN   \n",
       "2          6.0    0.5      0.5        1.00           0.0        NaN   \n",
       "3          8.0    0.5      0.5        0.00           0.0        NaN   \n",
       "4        -52.0    0.0     -0.5        0.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3          6.80             2          1   \n",
       "1                    0.3         16.86             1          1   \n",
       "2                    0.3          8.30             1          1   \n",
       "3                    0.3          9.30             2          1   \n",
       "4                   -0.3        -52.80             3          1   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                  0.00  \n",
       "1                  2.75  \n",
       "2                  0.00  \n",
       "3                  0.00  \n",
       "4                  0.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e199119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('lpep_pickup_datetime', StringType(), True), StructField('lpep_dropoff_datetime', StringType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('RatecodeID', LongType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('ehail_fee', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('payment_type', LongType(), True), StructField('trip_type', LongType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_green_pd).schema"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15cb157e",
   "metadata": {},
   "source": [
    "StructType([\n",
    "types.StructField('VendorID', types.LongType(), True), \n",
    "types.StructField('lpep_pickup_datetime', types.TimestampType(), True), \n",
    "types.StructField('lpep_dropoff_datetime', types.TimestampType(), True), \n",
    "types.StructField('store_and_fwd_flag', types.StringType(), True), \n",
    "types.StructField('RatecodeID', types.LongType(), True), \n",
    "types.StructField('PULocationID', types.LongType(), True), \n",
    "types.StructField('DOLocationID', types.LongType(), True), \n",
    "types.StructField('passenger_count', types.LongType(), True), \n",
    "types.StructField('trip_distance', types.DoubleType(), True), \n",
    "types.StructField('fare_amount', types.DoubleType(), True), \n",
    "types.StructField('extra', types.DoubleType(), True), \n",
    "types.StructField('mta_tax', types.DoubleType(), True), \n",
    "types.StructField('tip_amount', types.DoubleType(), True), \n",
    "types.StructField('tolls_amount', types.DoubleType(), True), \n",
    "types.StructField('ehail_fee', types.DoubleType(), True),\n",
    "types.StructField('improvement_surcharge', types.DoubleType(), True), \n",
    "types.StructField('total_amount', types.DoubleType(), True), \n",
    "types.StructField('payment_type', types.LongType(), True), \n",
    "types.StructField('trip_type', types.LongType(), True), \n",
    "types.StructField('congestion_surcharge', types.DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab605957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8aa7c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_schema = types.StructType([\n",
    "types.StructField('VendorID', types.LongType(), True), \n",
    "types.StructField('lpep_pickup_datetime', types.TimestampType(), True), \n",
    "types.StructField('lpep_dropoff_datetime', types.TimestampType(), True), \n",
    "types.StructField('store_and_fwd_flag', types.StringType(), True), \n",
    "types.StructField('RatecodeID', types.IntegerType(), True), \n",
    "types.StructField('PULocationID', types.IntegerType(), True), \n",
    "types.StructField('DOLocationID', types.IntegerType(), True), \n",
    "types.StructField('passenger_count', types.IntegerType(), True), \n",
    "types.StructField('trip_distance', types.DoubleType(), True), \n",
    "types.StructField('fare_amount', types.DoubleType(), True), \n",
    "types.StructField('extra', types.DoubleType(), True), \n",
    "types.StructField('mta_tax', types.DoubleType(), True), \n",
    "types.StructField('tip_amount', types.DoubleType(), True), \n",
    "types.StructField('tolls_amount', types.DoubleType(), True), \n",
    "types.StructField('ehail_fee', types.DoubleType(), True),\n",
    "types.StructField('improvement_surcharge', types.DoubleType(), True), \n",
    "types.StructField('total_amount', types.DoubleType(), True), \n",
    "types.StructField('payment_type', types.IntegerType(), True), \n",
    "types.StructField('trip_type', types.IntegerType(), True), \n",
    "types.StructField('congestion_surcharge', types.DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b3c5e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/4\n",
      "processing data for 2020/5\n",
      "processing data for 2020/6\n",
      "processing data for 2020/7\n",
      "processing data for 2020/8\n",
      "processing data for 2020/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/11\n",
      "processing data for 2020/12\n"
     ]
    }
   ],
   "source": [
    "year = 2020\n",
    "\n",
    "for month in range(1,13):\n",
    "    print(f'processing data for {year}/{month}')\n",
    "    input_path = f'data/raw/green/{year}/{month:02d}/'\n",
    "    output_path = f'data/pq/green/{year}/{month:02d}/'\n",
    "    df_green = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(green_schema) \\\n",
    "        .csv(input_path)\n",
    "\n",
    "    df_green.repartition(4).write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f81ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to parquet files that going to have the shema that i defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0eabfee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same with yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f253326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_pd = pd.read_csv('data/raw/yellow/2021/01/yellow_tripdata_2021_01.csv.gz',nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "236df7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('tpep_pickup_datetime', StringType(), True), StructField('tpep_dropoff_datetime', StringType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', LongType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_yellow_pd).schema"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27bc1491",
   "metadata": {},
   "source": [
    "StructType([\n",
    "StructField('VendorID', LongType(), True), \n",
    "StructField('tpep_pickup_datetime', StringType(), True), \n",
    "StructField('tpep_dropoff_datetime', StringType(), True), \n",
    "StructField('passenger_count', LongType(), True), \n",
    "StructField('trip_distance', DoubleType(), True), \n",
    "StructField('RatecodeID', LongType(), True), \n",
    "StructField('store_and_fwd_flag', StringType(), True), \n",
    "StructField('PULocationID', LongType(), True), \n",
    "StructField('DOLocationID', LongType(), True), \n",
    "StructField('payment_type', LongType(), True), \n",
    "StructField('fare_amount', DoubleType(), True), \n",
    "StructField('extra', DoubleType(), True), \n",
    "StructField('mta_tax', DoubleType(), True), \n",
    "StructField('tip_amount', DoubleType(), True), \n",
    "StructField('tolls_amount', DoubleType(), True), \n",
    "StructField('improvement_surcharge', DoubleType(), True), \n",
    "StructField('total_amount', DoubleType(), True), \n",
    "StructField('congestion_surcharge', DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "325ce842",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_schema = types.StructType([\n",
    "types.StructField('VendorID', types.LongType(), True), \n",
    "types.StructField('tpep_pickup_datetime', types.TimestampType(), True), \n",
    "types.StructField('tpep_dropoff_datetime', types.TimestampType(), True),\n",
    "types.StructField('passenger_count', types.IntegerType(), True),\n",
    "types.StructField('trip_distance', types.DoubleType(), True), \n",
    "types.StructField('RatecodeID', types.IntegerType(), True), \n",
    "types.StructField('store_and_fwd_flag', types.StringType(), True),\n",
    "types.StructField('PULocationID', types.IntegerType(), True), \n",
    "types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "types.StructField('payment_type', types.IntegerType(), True),\n",
    "types.StructField('fare_amount', types.DoubleType(), True), \n",
    "types.StructField('extra', types.DoubleType(), True), \n",
    "types.StructField('mta_tax', types.DoubleType(), True), \n",
    "types.StructField('tip_amount', types.DoubleType(), True), \n",
    "types.StructField('tolls_amount', types.DoubleType(), True), \n",
    "types.StructField('improvement_surcharge', types.DoubleType(), True), \n",
    "types.StructField('total_amount', types.DoubleType(), True),  \n",
    "types.StructField('congestion_surcharge', types.DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9623bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(yellow_schema) \\\n",
    "    .csv('data/raw/yellow/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "662fdea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 119:>                                                        (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 119:==============>                                          (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/home/antonis_hotmail/notebooks/data/raw/yellow/2021/08",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2108/521876810.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/raw/yellow/{year}/{month:02d}/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/pq/yellow/{year}/{month:02d}/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf_yellow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myellow_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/home/antonis_hotmail/notebooks/data/raw/yellow/2021/08"
     ]
    }
   ],
   "source": [
    "year = 2021\n",
    "\n",
    "for month in range(1,13):\n",
    "    print(f'processing data for {year}/{month}')\n",
    "    input_path = f'data/raw/yellow/{year}/{month:02d}/'\n",
    "    output_path = f'data/pq/yellow/{year}/{month:02d}/'\n",
    "    df_yellow = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(yellow_schema) \\\n",
    "        .csv(input_path)\n",
    "\n",
    "    df_yellow.repartition(4).write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9a9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
